# 2025-04-25

- Day 2
- Date: 2025-04-25
- Author: Richel

My session went reasonably well. I felt tight on time,
and there were 2 technical problems, 
but success rates were high (see below) anyways.

I've seen that a colleague discussed how to get the tarball
in her session. Maybe it should be moved to her session?
Nah, it fit fine within mine. Instead, just remind.

- [ ] Remind colleague that I do the tarball exercise

There was a technical problem: my computer partially froze while
discussing the exercise. Learners said they could still hear
me. As I was nearly done talking, I just said them to work from
this clumsy setting. I gave them 5 minute to work individually
on the exercise. During those 5 minutes, I logged out
and logged in again. All in time! I was happy with this
improvisation.

Due to this, there was another technical problem: my rights
as host were lost. This meant that I could not create breakout rooms.
I improvised: I gave the learner and end time, up until they could
do anything they wanted: I even encouraged them to take off their
headset, as (1) I want them to work undisturbed, and (2) I would
take questions in the main room. This worked out reasonably well.
I was happy again with my improvisation, although it would have been
more fun/useful for the learners to have worked in groups: it
also made me more blind of their progress ... but, hey, it was
the best I could do :-)

In the end, I did ask the progress of the learners:

- 13 out of 13 were able to use a Python module
    - This 1 learner struggled with logging in to Dardel
- 12 out of 14 installed the tarball
    - 1 is the 1 learner above
    - For the other learner is unknown why this did not work.
      I forgot to make a note who this was

Regardless of the hassle, most learners
were able to complete the exercises.

I think the camera recordings do more harm than good,
as it kills interactivity during class, at the minimal gain
of people outside of class being able to see these recording:

- Using live recordings as a supplementary tool may not be worth it in our settings,
  as 'No performance advantage was found for viewing recordings despite students'
  positive perception of their utility.'
  [Lesser, Melissa, and Lora Packel. "Educational Lessons from a Pandemic: 
  Lecture Recording and Learning Outcomes." 
  Internet Journal of Allied Health Sciences and Practice 22.2 (2024): 9., 
  [Link to paper](https://nsuworks.nova.edu/ijahsp/vol22/iss2/9/)]
- 'The main finding is that students using the online lectures 
  as a substitute for attending lectures are ultimately 
  at a fairly severe disadvantage in terms of their final marks'
  [Williams, Andrew, Elisa Birch, and Phil Hancock. "The impact of online lecture recordings on student performance."
  Australasian Journal of Educational Technology 28.2 (2012), 
  [Link to paper](https://ajet.org.au/index.php/AJET/article/view/869)].
- I found most experimental papers do not compare with live recording (it
  is usual pre-recorded versus an unrecorded/live lesson).
  The exception is a paper that does recommend the recording live webinars,
  although it admits that 
  '[Webinars tend] to be less engaging and less interactive for the participant'
  [Dailey-Hebert, Amber. "Maximizing interactivity in online learning: 
  Moving beyond discussion boards." Journal of Educators Online 15.3 (2018): n3.,
  [paper](https://eric.ed.gov/?id=EJ1199230)].

- [ ] Suggest this in a meeting

For the course as a whole, think following the
  pedagogic literature has a bigger impact over reading evaluations.

- For example 'long lectures and presentations will fail because students stop viewing and listening
  after about six minutes'
  [Nilson, Linda B., and Ludwika A. Goodson. Online teaching at its best: 
  Merging instructional design with teaching and learning research. John Wiley & Sons, 2021].
  From the same book, the 25 principes of learning from cognitive science (chapter 4, page 92)
  gives some great pointers, e.g. '2. Students learn [...] better [...] by engaging in an activity
  than when they passively watch [...] an instructor', 
  '6. Some qualities [...] help students learn [...] better [...]: human faces, [...] instructor enthusiasm'.

- [ ] Suggest this in a meeting

## Overview of how time is spent

Hour|Lecture (mins)|Dialogue (mins)|Exercises (mins)
----|--------------|---------------|----------------
1   |15            |5              |30
2   |35            |4              |11
3   |38            |5              |0
3.75|17            |0              |0
4   |49            |11             |0
5   |54            |2              |0
6   |0             |2              |28

### [Pace](../../evaluations/20250425_day_2/pace.txt)

- the pacing was good. I really liked the course material.
- Fast on the second day

I assume this is not about my session, as 60% of its time there
was time for exercises.

- great
- I think it was good, I could keep up and take notes during all of the lectures.
- I feel like it was a bit rushed, good content but a bit too much given
  the amount of time maybe?

I assume this is not about my session, as 60% of its time there
was time for exercises.

- It was a lot of information to take in.
  However the resources provided are sufficient to catch up if we were
  stuck anywhere.
- Good
- It was the right pace
- I did not feel comfortable during the afternoon session was running too fast,
  just to adjust to the schedule and got few from that and was confused
  because of several concepts in a bunch without explain the practical examples
  I guess it is been assumed that everybody knows all the concepts.

Not my session.

- Too fast to combine explanations and exercises

I assume this is not about my session, as 60% of its time there
was time for exercises.

- Good pace considering the amount of materials and time.
  Then one needs to practise home by rewatching the YT videos

Hmmm, in general, I find that live recordings have
'No performance advantage was found for viewing recordings despite students'
positive perception of their utility.'
[Lesser, Melissa, and Lora Packel. "Educational Lessons from a Pandemic: 
Lecture Recording and Learning Outcomes." 
Internet Journal of Allied Health Sciences and Practice 22.2 (2024): 9., 
[Link to paper](https://nsuworks.nova.edu/ijahsp/vol22/iss2/9/)].
However, that paper does find positive effects for learners that, like
here, use it after attending a session.

- Inconsistent - seemed slow much of the time, while some parts passed by
  before they could be properly explained or understood: it seemed to me that
  the time was not spent on the right things. I know enough about Python,
  I do not know enough about the software module system and SLURM
  and any other HPC-specific stuff.

I assume this is not about my session, as 60% of its time there
was time for exercises.

However, I will suggest to do more foundational things at Day 2

- [ ] Suggest to do more foundational things at Day 2 in a meeting

- Too fast

I assume this is not about my session, as 60% of its time there
was time for exercises.

- okish
- Suitable

### [Future topics](../../evaluations/20250425_day_2/future_topics.txt)

- Xarray and dask
- it is totally enough for me to study this content, and the document is great,
  I can read the document to revise the lesson
- It could be helpful to have a lecture about R as well.

I don't think R should be part of a Python course.
But hey, I can link to it

- [ ] Link to R course

- More information on the HPC environment within a similar context. Maybe focusing on one HPC centre at a time.
- Topics are ok. Just give more profound and practical demos during the sessions.
- A summary of options in using Python in the HPC, with suggestions and best practices. What to do when the default modules are not enough.
- This 2nd day and we have not going through ML and Deep learning PyTorch and Tensorflow GPU: PINNs, Quantum ML (PennyLane, Qiskit) or small LLM
- matplotlib from a regular shell/interactive/in compute jobs
- How to find compatible modules and packages

### [Other comments](comments.txt)

- every thing is great for me
- I think all of the training materials were very clear, and I liked the amount of hands-on exercises. I also really appreciated how supportive all of the teachers were, the classes had a very nice atmosphere.
- Overall, a great session, but it would be great to have more time plannned into each session for questions.
- For the matplotlib part: to improve more demonstrations rather than read so quickly the content to accomplish the schedule. Improve the depth of the course not too superficial to at least catch some key points that helps to start.  The morning session had better demo and I could follow the steps.
- The written material is quite good and shows the different options, but simply going through them during the course takes too long and sometimes end up with focus on specific HPC systems that not everyone is going to use. There are instructions for each cluster, so maybe the topics should be more generic with access to the specific info as needed. The IDE section, for example, could only show how to do it to very specific cases, while having the cluster instructions and a generic discussion about the options could be better.
- Overall very good docs from each mentors that states pro and contro and niche details of each HPC. Infinite for trouble-shooting support especially for beginners
- (did not attend Matplotlib part) 1. Overall the reading/presentation material was good to very good, just too far between exercises - as soon as one step has been explained, I want to test it and make sure I can do it! But some information was outdated and some part or parts had lots of spelling errors.  2. Again and again, there was not enough time margins within each session. Asking us to do stuff on the breaks is BAD. Breaks are needed for food, toilet and looking away from the screen. Can't learn anything if we don't get breaks.  3. Lunch break start and end time needs to be confirmed before 12:00. For those of us caught up in listening and following along it got cut much too short today.
- It's good that you record, but could you post the recordings a bit faster so we can go through before the rest of the course?
- Not fond of the IDEs, I think it's unnecessarily cumbersome. Shell is much easier to work in. You don't have to load a lot of other things, set graphics and fight with it :( Why this focus on jupyter or spyder or whatever it was called

## [Detailed feedback from a learner](../../evaluations/202504_course/evaluation_202504_full_course.md)

NB: On the first day, with Richel, I was mostly in the role of a TA rather
than a learner. I did not fill out the feedback form for that day,
but I had an immediate evaluation meeting with Richel at the end of the day.

NB 2: I did fill out the feedback evaluation form for the three remaining days,
and did not look back on what I wrote then (or look at the course evaluation
results at all) while writing this. Therefore this document probably duplicates
some of that while being feedback from a single (and perhaps not the most
representative) learner.

NB 3: I did not attend the matplotlib sessions.

## A multitude of teachers

This is GREAT! Some variation in perspective, focus and intensity makes a big
difference and is much appreciated. Anders Hast deserves special mention for
bringing true researcher enthusiasm, it is great to learn from teachers that
know and enjoy the subject at hand like that.

Sometimes a useful connection between two different sessions gets more or less
lost, e.g. mentioning line-by-line file IO from the first day when talking
about file formats at the end of day 3 would be easier to do well in a
traditional one-teacher-per-course format.
For this course I deem these losses very small and acceptable,
especially in the light of the advantages mentioned above.

However, the contrast between sessions pulls into sharp focus a few things to
improve upon:

Preparedness is key

Several sessions had examples, code-alongs or exercises that did not work as
intended without troubleshooting that was not within the focus of the session.
Learning about modules and packages and handling the dependency hell in various
ways is very good (I'll get back to this), but it is not good to be
interrupted by these things when trying to teach and learn something else.

It would be good if all of the course materials, for all of the clusters,
was confirmed working as intended before the course.[1] I do realize that this
is a big undertaking—but make no mistake, this course (with the amount of
content it currently has) is definitely a big undertaking.

Too much content, too little time

Full days leave little to zero time for going through the exercises on our own.
Having extra exercises for repeating and/or diving deeper after the course is
good, but all that is truly intended to be part of the course needs to be given
the time within the course. With no time to test and get some confidence that
one part is understood and doable, open questions and uncertainty cause
several problems for learners.

First, it immediately steals away some focus/brainpower. Second, we might not
get knowledge/skill presumed by later parts of the course. Third, the sheer
worry of the latter is not to be trifled with! I have seen that wreak havoc
on learning again and again in various lectures and labs.

The sessions on Pandas and Seaborn especially were much too rushed, to the point
that they felt close to useless. The session on IDEs had barely enough time for
me to get Jupyter running, while I would've expected to try VS Code and Spyder
as well since all of them are in there. The course taken as a whole also needs
either less content or more time.

To solve this nicely, please consider what content is crucial that learners get
to try and to ask questions about! The rest can be left in extras for the
learners to look at after the course. This is closely related to how general
a topic is, if there are many other places to ask questions
and get the right answers.

We learn what we do

In some sessions, mainly Parallellism and ML/DL if I recall correctly,
I was learning about modules and packages and lost track of the lecture as
I was trying to make the examples work. In some sessions I learned little
to nothing as I found no time to try anything. In some sessions I got to try
and learn every single thing that was in the course materials.

There seems to be two good ways to have learners actually do stuff in an
online course. One is what Richel does: most of the time in 2-person breakout
rooms, working through exercises as the main way of learning.

Another one is to have a well-prepared code notebook with
demos/examples/exercises to be completed by the learners.
On desktop screens and larger laptops learners can have their copy of the
notebook side-by-side with the meeting.
This method can smoothly intersperse both longer and very short bits of
hands-on coding into a lecture, akin to how the demos that weren't working in
the sessions on Parallel programming should have worked.

## Focus and structure

This course teaches many separate things. This gets a bit too messy,
both for the learners who do need to learn all of it—these people are new to
the entirety of this and will not be able to group and separate things—and
for the learners who only needs selected parts of the course.

It would be easier for both groups (though a bit less efficient,
for those who both need all of it and are somehow able to efficiently learn
it the way it is now) if this content was divided between as much as
four separate courses:

- Intro to HPC, usage and management of software and code 
  (Logging in, LMOD, SLURM; the things that are actually different
  between HPC and a single-user single computer)
- Intro to Python (this already exists and is day 1)
- Python coding for big computation, big data and AI (this includes parallell
  and GPU but is not specific to HPC and probably exists elsewhere)
- Using Python code, packages and environments at NAISS HPC systems
  (LMOD, venv, conda; when to use what and how they interact)

Course 1 is general to HPC users, not specific to Python. It should probably be provided by NAISS quite often and be a prerequisite to all other NAISS courses. Courses 2 and 3 are general to Python users, not specific to HPC, widely available from elsewhere. Course 4 is specific to Python in HPC; this is what I, a seasoned learner, would expect NAISS to provide in regards to using Python.

## What I expected (or hoped) to learn that I did not learn

Essentially the fourth course mentioned above. I have not acquired the one
skill (AFAIK) that is truly specific to Python on HPC: how to choose how to
manage the packages. Everything else (that was in this course) is shared with
either other HPC users or other Python users—therefore it is discussed and
taught by other resources—so this is what I truly wanted from this course.
I did learn a bit about it but it seemed to happen by accident as much or
more than as a result of the course truly focussing on this matter.

The fix would be to make sure every single command that loads a module or a python package does specify a specific version. Well, for the recurring problem that I do remember, but there may have been more problems. ↩︎
