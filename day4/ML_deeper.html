

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>More about ML &mdash; Using Python in an HPC environment 2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_lesson.css?v=e9df6548" />
      <link rel="stylesheet" type="text/css" href="../_static/term_role_formatting.css?v=4194e21c" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_rtd_theme_ext_color_contrast.css?v=8e8ea19f" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
      <link rel="stylesheet" type="text/css" href="../_static/thebelab.css" />
      <link rel="stylesheet" type="text/css" href="../_static/custom_theme.css?v=7da4766e" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=a5c4661c" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=60dbed4a"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=6dbb43f8"></script>
      <script src="../_static/minipres.js?v=a0d29692"></script>
      <script src="../_static/thebelab-helper.js"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
      <script src="../_static/design-tabs.js?v=f930bc37"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script src="../_static/tabs.js?v=3030b3cb"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="On UPPMAX clusters" href="../uppmax.html" />
    <link rel="prev" title="On Kebnekaise cluster" href="../kebnekaise.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Using Python in an HPC environment
              <img src="../_static/hpc2n-lunarc-uppmax-hpc-course.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Pre-requirements:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../prereqs.html">Pre-requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preparations.html">Prepare the environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Common:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../schedule.html">Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/login.html">Log in and other preparations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/use_tarball.html">Use the tarball with exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/use_text_editor.html">Use a text editor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/understanding_clusters.html">HPC clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../common/naiss_projects_overview.html">NAISS projects overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Lessons day 1 (Intro to Python):</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../common/day1.html">Link to Day 1 (Intro to Python)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Lessons day 2 (packages and analysis):</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../day2/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/use_packages.html">Using packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/install_packages.html">Install packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/use_isolated_environments.html">Use isolated environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/basic_batch_slurm.html">Basic batch and Slurm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/interactive.html">Interactive work on the compute nodes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/ondemand-desktop.html">Desktop On Demand</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/IDEs_cmd.html">Starting IDEs from command line</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/IDEs.html">Using IDEs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../summary2.html">Summary day 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day2/python_at_hpc_centers.html">Python documentations at the different HPC centres</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Lessons day 3 (advanced analysis):</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../day3/new-matplotlib-intro.html">A Brief Intro to Matplotlib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day3/pandas.html">Intro to Pandas on HPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day3/seaborn-new.html">A Brief Introduction to the Seaborn Statistical Plotting Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day3/big_data.html">Big data with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day3/batch-new.html">Running Python in batch mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../summary3.html">Summary day 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../day3/evaluation.html">Evaluation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Lessons day 4 (parallel and ML):</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="parallel.html">Parallel computing with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu.html">Using GPUs with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml.html">Machine Learning and Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="dim_reduction.html">Dimensionality Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../summary4.html">Summary day 4</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extra:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../bianca.html">On Bianca cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extra/other_courses.html">Other courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extra/packages_deeper.html">More about packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extra/isolated_deeper.html">Developing in isolated environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extra/jupyterHPC2N.html">Jupyter at Kebnekaise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kebnekaise.html">On Kebnekaise cluster</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">More about ML</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#horovod">Horovod</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../uppmax.html">On UPPMAX clusters</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Using Python in an HPC environment</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">More about ML</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/UPPMAX/HPC-python/blob/main/docs/day4/ML_deeper.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="more-about-ml">
<h1>More about ML<a class="headerlink" href="#more-about-ml" title="Link to this heading"></a></h1>
<p>This section contains one more example for ML.</p>
<section id="horovod">
<h2>Horovod<a class="headerlink" href="#horovod" title="Link to this heading"></a></h2>
<p>As the training is one of the most computationally demanding steps in a ML workflow,
it would be worth it to optimize this step. Horovod is a framework dedicated to
make more efficient the training step by distributing the workload across several
nodes, each consisting of some CPUs and GPUs. An example on the usage of Horovod
can be found in the course <a class="reference external" href="https://enccs.github.io/upscalingAI/hvd_intro/">Upscaling AI workflows</a>
offered by ENCCS.</p>
<blockquote>
<div><div class="dropdown admonition">
<p class="admonition-title"><code class="docutils literal notranslate"><span class="pre">Transfer_Learning_NLP_Horovod.py</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">argparse</span>

<span class="c1"># Suppress tensorflow logging outputs</span>
<span class="c1"># os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &quot;2&quot;</span>

<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">logdir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">())</span><span class="o">/</span><span class="s2">&quot;tensorboard_logs&quot;</span>
<span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">logdir</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Parse input arguments</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;Transfer Learning Example&#39;</span><span class="p">,</span>
                                 <span class="n">formatter_class</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentDefaultsHelpFormatter</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--log-dir&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">logdir</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;tensorboard log directory&#39;</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--num-worker&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;number of workers for training part&#39;</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--batch-size&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;input batch size for training&#39;</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--base-lr&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;learning rate for a single GPU&#39;</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--epochs&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;number of epochs to train&#39;</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--momentum&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;SGD momentum&#39;</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--target-accuracy&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">.96</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Target accuracy to stop training&#39;</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--patience&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Number of epochs that meet target before stopping&#39;</span><span class="p">)</span>

<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--use-checkpointing&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">)</span>

<span class="c1"># Step 10: register `--warmup-epochs`</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--warmup-epochs&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s1">&#39;number of warmup epochs&#39;</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="c1"># Define a function for a simple learning rate decay over time</span>

<span class="k">def</span> <span class="nf">lr_schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">15</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">args</span><span class="o">.</span><span class="n">base_lr</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">25</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">1e-1</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">base_lr</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">35</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">1e-2</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">base_lr</span>
    <span class="k">return</span> <span class="mf">1e-3</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">base_lr</span>

<span class="c1">##### Steps</span>
<span class="c1"># Step 1: import Horovod</span>
<span class="kn">import</span> <span class="nn">horovod.tensorflow.keras</span> <span class="k">as</span> <span class="nn">hvd</span>

<span class="n">hvd</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="c1"># Nomrally Step 2: pin to a GPU</span>
<span class="n">gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">gpus</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">set_memory_growth</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="k">if</span> <span class="n">gpus</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">(</span><span class="n">gpus</span><span class="p">[</span><span class="n">hvd</span><span class="o">.</span><span class="n">local_rank</span><span class="p">()],</span> <span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="c1"># Step 2: but in our case</span>
<span class="c1"># gpus = tf.config.list_physical_devices(&#39;GPU&#39;)</span>
<span class="c1"># if gpus:</span>
<span class="c1">#    tf.config.experimental.set_memory_growth(gpus[0], True)</span>

<span class="c1"># Step 3: only set `verbose` to `1` if this is the root worker.</span>
<span class="k">if</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Version: &quot;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hub version: &quot;</span><span class="p">,</span> <span class="n">hub</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU is&quot;</span><span class="p">,</span> <span class="s2">&quot;available&quot;</span> <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;NOT AVAILABLE&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of GPUs :&#39;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)))</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1">#####</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;dataset.pkl&#39;</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s1">&#39;dataset.pkl&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip&#39;</span><span class="p">,</span>
             <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;zip&#39;</span><span class="p">,</span> <span class="n">low_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s1">&#39;dataset.pkl&#39;</span><span class="p">)</span>

<span class="n">train_df</span><span class="p">,</span> <span class="n">remaining</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">valid_df</span><span class="p">,</span> <span class="n">_</span>  <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">remaining</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.09</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">remaining</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="k">if</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The shape of training </span><span class="si">{}</span><span class="s2"> and validation </span><span class="si">{}</span><span class="s2"> datasets.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">valid_df</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;##-------------------------##&quot;</span><span class="p">)</span>

<span class="n">buffer_size</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">size</span>
<span class="c1">#train_dataset = tf.data.Dataset.from_tensor_slices((train_df.question_text.values, train_df.target.values)).repeat(args.epochs*2).shuffle(buffer_size).batch(args.batch_size)</span>
<span class="c1">#valid_dataset = tf.data.Dataset.from_tensor_slices((valid_df.question_text.values, valid_df.target.values)).repeat(args.epochs*2).batch(args.batch_size)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">train_df</span><span class="o">.</span><span class="n">question_text</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">train_df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">valid_df</span><span class="o">.</span><span class="n">question_text</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">valid_df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">values</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">module_url</span> <span class="o">=</span> <span class="s2">&quot;https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1&quot;</span>
<span class="n">embeding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">name_of_model</span> <span class="o">=</span> <span class="s1">&#39;nnlm-en-dim128&#39;</span>

<span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">module_url</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">hub_layer</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">module_url</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">[</span><span class="n">embed_size</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">hub_layer</span><span class="p">,</span>
                                        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
                                        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
                                        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)])</span>

    <span class="c1"># Step 9: Scale the learning rate by the number of workers.</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">base_lr</span> <span class="o">*</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">momentum</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span>
    <span class="c1"># opt = tf.optimizers.Adam(learning_rate=args.base_lr * hvd.size())</span>

    <span class="c1">#Step 4: Wrap the optimizer in a Horovod distributed optimizer</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">DistributedOptimizer</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span>
                                   <span class="n">backward_passes_per_step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                   <span class="n">average_aggregated_gradients</span><span class="o">=</span><span class="kc">True</span>
                                   <span class="p">)</span>

    <span class="c1"># For Horovod: We specify `experimental_run_tf_function=False` to ensure TensorFlow</span>
    <span class="c1"># uses hvd.DistributedOptimizer() to compute gradients.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(),</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)],</span>
                <span class="n">experimental_run_tf_function</span> <span class="o">=</span> <span class="kc">False</span>
                 <span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Step 5: broadcast initial variable states from the first worker to</span>
<span class="c1"># all others by adding the broadcast global variables callback.</span>
<span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hvd</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">BroadcastGlobalVariablesCallback</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># Step 7: average the metrics among workers at the end of every epoch</span>
<span class="c1"># by adding the metric average callback.</span>
<span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hvd</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">MetricAverageCallback</span><span class="p">())</span>

<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">use_checkpointing</span><span class="p">:</span>
    <span class="c1"># TensorFlow normal callbacks</span>
    <span class="n">callbacks</span><span class="o">.</span><span class="n">apped</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">))</span>

    <span class="c1"># Step 8: checkpointing should only be done on the root worker.</span>
    <span class="k">if</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">callbacks</span><span class="o">.</span><span class="n">apped</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">logdir</span><span class="o">/</span><span class="n">name_of_model</span><span class="p">))</span>

<span class="c1"># Step 10: implement a LR warmup over `args.warmup_epochs`</span>
<span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hvd</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LearningRateWarmupCallback</span><span class="p">(</span><span class="n">initial_lr</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">base_lr</span><span class="p">,</span> <span class="n">warmup_epochs</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">warmup_epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">))</span>

<span class="c1"># Step 10: replace with the Horovod learning rate scheduler,</span>
<span class="c1"># taking care not to start until after warmup is complete</span>
<span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hvd</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LearningRateScheduleCallback</span><span class="p">(</span><span class="n">initial_lr</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">base_lr</span><span class="p">,</span> <span class="n">start_epoch</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">warmup_epochs</span><span class="p">,</span> <span class="n">multiplier</span><span class="o">=</span><span class="n">lr_schedule</span><span class="p">))</span>


<span class="c1"># Creating model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">module_url</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="n">embeding_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name_of_model</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="k">if</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">##-------------------------##&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training starts ...&quot;</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                    <span class="c1"># Step 6: keep the total number of steps the same despite of an increased number of workers</span>
                    <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="p">)</span> <span class="o">//</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
                    <span class="c1"># steps_per_epoch = ( 5000 ) // hvd.size(),</span>
                    <span class="n">workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_worker</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_dataset</span><span class="p">,</span>
                    <span class="c1">#Step 6: set this value to be 3 * num_test_iterations / number_of_workers</span>
                    <span class="n">validation_steps</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="p">(</span><span class="n">valid_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span> <span class="p">)</span> <span class="o">//</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
                    <span class="c1"># validation_steps = ( 5000 ) // hvd.size(),</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
                    <span class="c1"># use_multiprocessing = True,</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

<span class="n">endt</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">start</span>

<span class="k">if</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Elapsed Time: </span><span class="si">{}</span><span class="s2"> ms&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">1000</span><span class="o">*</span><span class="n">endt</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;##-------------------------##&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div></blockquote>
<p>The following steps need to be performed before running this example:</p>
<div class="dropdown admonition important">
<p class="admonition-title">Important</p>
<blockquote>
<div><p><strong>Prerequisites</strong></p>
<ul>
<li><p>For Kebnekaise:</p>
<p>ml GCC/10.2.0 CUDA/11.1.1 OpenMPI/4.0.5
ml TensorFlow/2.4.1
ml Horovod/0.21.1-TensorFlow-2.4.1</p>
<p>virtualenv –system-site-packages /proj/nobackup/&lt;your-project-storage&gt;/env-horovod</p>
<p>source /proj/nobackup/&lt;your-project-storage&gt;/env-horovod/bin/activate</p>
<p>python -m pip install  tensorflow_hub</p>
<p>python -m pip install  sklearn</p>
</li>
<li><p>For Rackham/Snowy:</p>
<p>module load python_ML_packages python/3.9.5 gcc/10.3.0 build-tools cmake/3.22.2</p>
<p>cd /proj/hpc-python/&lt;mydir-name&gt;
python -m venv –system-site-packages env-horovod</p>
<p>source /proj/hpc-python/&lt;mydir-name&gt;/env-horovod/bin/activate</p>
<p>pip install –no-cache-dir –no-build-isolation horovod</p>
<p>pip install –no-cache-dir –no-build-isolation tensorflow-hub</p>
</li>
</ul>
</div></blockquote>
</div>
<p>A sample batch script for running this Horovod example is here:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">UPPMAX</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">HPC2N</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash -l</span>
<span class="c1">#SBATCH -A naiss2024-22-415</span>
<span class="c1">#SBATCH -t 00:05:00</span>
<span class="c1">#SBATCH -M snowy</span>
<span class="c1">#SBATCH -n 1</span>
<span class="c1">#SBATCH -o output_%j.out   # output file</span>
<span class="c1">#SBATCH -e error_%j.err    # error messages</span>
<span class="c1">#SBATCH --gres=gpu:1</span>

<span class="c1"># Set a path where the example programs are installed.</span>
<span class="c1"># Change the below to your own path to where you placed the example programs</span>
<span class="nv">MYPATH</span><span class="o">=</span>/proj/hpc-python/&lt;mydir-name&gt;/HPC-python/Exercises/examples/programs/

ml<span class="w"> </span>purge
module<span class="w"> </span>load<span class="w"> </span>uppmax
module<span class="w"> </span>load<span class="w"> </span>python_ML_packages<span class="w"> </span>python/3.9.5
module<span class="w"> </span>load<span class="w"> </span>gcc/10.3.0<span class="w"> </span>build-tools<span class="w"> </span>cmake/3.22.2

<span class="c1"># Change the below to your own path to the virtual environment you installed horovod to</span>
<span class="nb">source</span><span class="w"> </span>/proj/hpc-python/&lt;mydir-name&gt;/env-horovod/bin/activate

srun<span class="w"> </span>python<span class="w"> </span><span class="nv">$MYPATH</span>/Transfer_Learning_NLP_Horovod.py<span class="w"> </span>--epochs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--batch-size<span class="w"> </span><span class="m">64</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH -A project_ID</span>
<span class="c1">#SBATCH -t 00:05:00</span>
<span class="c1">#SBATCH -N X               # nr. nodes</span>
<span class="c1">#SBATCH -n Y               # nr. MPI ranks</span>
<span class="c1">#SBATCH -o output_%j.out   # output file</span>
<span class="c1">#SBATCH -e error_%j.err    # error messages</span>
<span class="c1">#SBATCH --gres=gpu:k80:2</span>
<span class="c1">#SBATCH --exclusive</span>

ml<span class="w"> </span>purge<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span>
ml<span class="w"> </span>GCC/10.2.0<span class="w"> </span>CUDA/11.1.1<span class="w"> </span>OpenMPI/4.0.5
ml<span class="w"> </span>TensorFlow/2.4.1
ml<span class="w"> </span>Horovod/0.21.1-TensorFlow-2.4.1

<span class="nb">source</span><span class="w"> </span>/proj/nobackup/&lt;your-project-storage&gt;/env-horovod/bin/activate

<span class="nv">list_of_nodes</span><span class="o">=</span><span class="k">$(</span><span class="w"> </span>scontrol<span class="w"> </span>show<span class="w"> </span>hostname<span class="w"> </span><span class="nv">$SLURM_JOB_NODELIST</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sed<span class="w"> </span>-z<span class="w"> </span><span class="s1">&#39;s/\n/\:4,/g&#39;</span><span class="w"> </span><span class="k">)</span>
<span class="nv">list_of_nodes</span><span class="o">=</span><span class="si">${</span><span class="nv">list_of_nodes</span><span class="p">%?</span><span class="si">}</span>
mpirun<span class="w"> </span>-np<span class="w"> </span><span class="nv">$SLURM_NTASKS</span><span class="w"> </span>-H<span class="w"> </span><span class="nv">$list_of_nodes</span><span class="w"> </span>python<span class="w"> </span>Transfer_Learning_NLP_Horovod.py<span class="w"> </span>--epochs<span class="w"> </span><span class="m">10</span><span class="w"> </span>--batch-size<span class="w"> </span><span class="m">64</span>
</pre></div>
</div>
</div></div>
<div class="admonition-running-the-horovod-example exercise important admonition" id="exercise-0">
<p class="admonition-title">Running the Horovod example</p>
<p>Do the initial steps for loading the required modules for Horovod, create
an environment and install the dependencies for Horovod.</p>
<p>Run the Horovod example on 1 node each with 4 GPU engines. Thus, 4 MPI ranks
will be needed. Then run the script on 2 nodes. Compare the wall times reported
at the end of the output files.</p>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../kebnekaise.html" class="btn btn-neutral float-left" title="On Kebnekaise cluster" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../uppmax.html" class="btn btn-neutral float-right" title="On UPPMAX clusters" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, UPPMAX/HPC2N/LUNARC/InfraVis.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>